2510.25720v1 [nucl-ex] 29 Oct 2025

ww XIV

a

©

Eur. Phys. J. C manuscript No.
(will be inserted by the editor)

End-to-End Data Analysis Methods for the CUORE
Experiment

D. Q. Adams!, C. Alduino!, K. Alfonso”, A. Armatol*®, F. T. Avignone III', O. Azzolini*,

G. Bari®, F. Bellini®’, G. Benato®’, M. Beretta!®:!!, M. Biassoni!!, A. Branca!?:!!, C. Brofferio!!',
C. Bucci’, J. Camilleri?, A. Caminata'?, A. Campani!*!?, J. Cao!*, C. Capelli®, S. Capelli!?",

L. Cappelli®, L. Cardani’, P. Carniti!?:'!, N. Casali’, E. Celi®:°, D. Chiesa!!!, M. Clemenza",

S. Copello'®, O. Cremonesi'!!, R. J. Creswick!, A. D’Addabbo’, I. Dafinei’, S. Dell’Oro!!!,

S. Di Domizio™:*, S. Di Lorenzo®, T. Dixon'®, D. Q. Fang!*+, M. Faverzani!®!!, E. Ferri!',

F. Ferroni®”, E. Fiorini!®!!>, M. A. Franceschi!’, S. J. Freedman*!*°, S.H. Fu’!4, B. K. Fujikawa’,
S. Ghislandi®’, A. Giachero!'', M. Girola!®!!, L. Gironi!?"', A. Giuliani!®, P. Gorla®, C. Gotti",
P. V. Guillaumon®, T. D. Gutierrez!®, K. Han”, E. V. Hansen!*, K. M. Heeger?!, D. L. Helis’,
H. Z. Huang”’, M. T. Hurst”*, G. Keppel’, Yu. G. Kolomensky!*?, R. Kowalski**, R. Liu?',

L. Ma!4?, Y. G. Ma!4, L. Marini®, R. H. Maruyama?!, D. Mayer!®*:?>, Y. Mei?, M. N. Moore?!,
T. Napolitano’, M. Nastasi!°:!!, C. Nones?°, E. B. Norman?’, A. Nucciotti!?!', I. Nutini!',

T. O’Donnell?, M. Olmi’, B. T. Oregui?*, S. Pagan?!, C. E. Pagliarone®?*, L. Pagnanini®’,

M. Pallavicini!®:’, L. Pattavina!?!!, M. Pavan!?:"!, G. Pessinal', V. Pettinacci’, C. Pira*, S. Pirro’,
E. G. Pottebaum”', S. Pozzi!', E. Previtali!®!!, A. Puiu’, S. Quitadamo*’, A. Ressa’, C. Rosenfeld’,
B. Schmidt?®, R. Serino!®!°, A. Shaikina®°, V. Sharma?*, V. Singh", M. Sisti'!, D. Speller?*,

P. T. Surukuchi?*, L. Taffarello?®, C. Tomei’, A. Torres’, J. A. Torres”!, K. J. Vetter?>:!®*°,

M. Vignati®’, S. L. Wagaarachchi!*, B. Welliver'®’, J. Wilson'!, K. Wilson', L. A. Winslow?°,

F. Xie!*, T. Zhu'®, S. Zimmermann®’, S. Zucchelli®!°

+Department of Physics and Astronomy, University of South Carolina, Columbia, SC 29208, USA

2Center for Neutrino Physics, Virginia Polytechnic Institute and State University, Blacksburg, Virginia 24061,USA
’Nuclear Science Division, Lawrence Berkeley National Laboratory, Berkeley, CA 94720, USA

4INFN — Laboratori Nazionali di Legnaro, Legnaro (Padova) I-35020, Italy

SINEN - Sezione di Bologna, Bologna I-40127, Italy

°Dipartimento di Fisica, Sapienza Universita di Roma, Roma [-00185, Italy

TINFN — Sezione di Roma, Roma I-00185, Italy

8Gran Sasso Science Institute, L’Aquila I-67100, Italy

%INEN - Laboratori Nazionali del Gran Sasso, Assergi (L’ Aquila) 1-67100, Italy

1°Dipartimento di Fisica, Université di Milano-Bicocca, Milano I-20126, Italy

11INFN — Sezione di Milano Bicocca, Milano I-20126, Italy

12INFN — Sezione di Genova, Genova I-16146, Italy

13Dipartimento di Fisica, Universita di Genova, Genova I-16146, Italy

14Key Laboratory of Nuclear Physics and Ion-beam Application (MOE), Institute of Modern Physics, Fudan
University,Shanghai 200433, China

15INFN — Sezione di Pavia, Pavia I-27100, Italy

16Université Paris-Saclay, CNRS/IN2P3, IJCLab, 91405 Orsay, France

17INFN — Laboratori Nazionali di Frascati, Frascati (Roma) 1-00044, Italy

18Department of Physics, University of California, Berkeley, CA 94720, USA

19Physics Department, California Polytechnic State University, San Luis Obispo, CA 93407, USA

20INPAC and School of Physics and Astronomy, Shanghai Jiao Tong University; Shanghai Laboratory for Particle Physics
and Cosmology, Shanghai 200240, China

21 Wright Laboratory, Department of Physics, Yale University, New Haven, CT 06520, USA

?2Department of Physics and Astronomy, University of California, Los Angeles, CA 90095, USA

23Department of Physics and Astronomy, University of Pittsburgh, Pittsburgh, PA 15260, USA

24Department of Physics and Astronomy, The Johns Hopkins University, 3400 North Charles Street Baltimore, MD,21211
25Massachusetts Institute of Technology, Cambridge, MA 02139, USA

26TRFU, CEA, Université Paris-Saclay, F-91191 Gif-sur-Yvette, France

27Department of Nuclear Engineering, University of California, Berkeley, CA 94720, USA

28Dipartimento di Ingegneria Civile e Meccanica, Universita degli Studi di Cassino e del Lazio Meridionale, Cassino 1-03043,
Italy

29INFN — Sezione di Padova, Padova I-35131, Italy

3°Engineering Division, Lawrence Berkeley National Laboratory, Berkeley, CA 94720, USA

31 Dipartimento di Fisica e Astronomia, Alma Mater Studiorum — Université di Bologna, Bologna I-40127, Italy
Received: date / Accepted: date

Abstract The Cryogenic Underground Observatory for
Rare Events (CUORE) experiment set the most strin-
gent limit on the neutrinoless double-beta (08) decay
half-life of 8°Te with 2t-yr TeOz analyzed exposure.
In addition to 0v88 decay, the CUORE detector—a
ton-scale array of nearly 1000 cryogenic calorimeters
operating at ~10 mK—is capable of searching for other
rare decays and interactions over a broad energy range.
For our searches, we leverage the available information
of each calorimeter by performing its optimization, data
acquisition, and analysis independently. We describe
the analysis tools and methods developed for CUORE
and their application to build high-quality datasets for
numerous physics searches. In particular, we describe in
detail our evaluation of the energy-dependent detector
response and signal efficiency used in the most recent
search for Ov decay.

Include keywords, PACS and mathematical subject
classification numbers as needed

Keywords Cryogenic calorimeters - Rare event
searches - Large scale particle detectors - Data analysis
- Digital signal processing - Analysis techniques

1 Introduction

CUORE (Cryogenic Underground Observatory for Rare
Events) [1,2] is a leading neutrinoless double-beta (038)
decay experiment. Compared to standard double-beta
decay, in which two neutrons in a nucleus conver
two protons with the emission of two electrons and two
anti-neutrinos, only electrons would be emitted in neu-
trinoless double-beta decay. Given the absence of neu-
trinos from the final state, the signature for this hypo-
thetical process is a monoenergetic peak at its Q-value
(Qgg), which is typically in the few-MeV range. Lower
limits on the half-life for this process range between
4.4 x 1074-2 x 1076 yr [1,3,4,5,6].
The CUORE detector employs cryogenic calorime-
ters to measure the energy of particle interactions and
decays. With this technique, the energy deposited by a
particle in an absorber material maintained at a tem-
perature of ~10 mK is converted into thermal phonons
(heat) and measured as a temperature variation. The
slight differences in the intrinsic properties of CUORE
detector components—i.e., absorber, temperature sen-
sor, etc.—across calorimeters, and their sheer number,

into

e-mail: cuore-spokesperson@Ings.infn. it

>Deceased

“Deceased

‘Presently at: Instituto de Fisica, Universidade de Sao Paulo,
Sao Paulo 05508-090, Brazil

necessitated the development of a calorimeter-depen-
dent readout chain [7,8,9] and new automated proce-
dures for the characterization and optimization of var-
ious detector parameters [10, 11,12, 13]. In comparison,
predecessor cryogenic calorimetric experiments utilized
at most tens of detectors and were on the kilogram scale
(14, 15].

In our analysis framework, each calorimeter is treat-
ed independently. When a particle deposits energy in a
CUORE crystal, a signal pulse forms in the temperature
sensor readout, which we measure as voltage. The signal
waveform, u(t), of each detector can be modeled as the
sum of a detector response function, s(t), and a noise
term, n(t):

v(t) =b+ A+ s(t —to) + n(t) (1)

where b is the DC level (baseline) of the detector sensor,
A is the amplitude of the signal, t is time, and to is
the start time of the pulse relative to a defined event
window.

In this paper, we describe how each component in
Eq. 1 is determined for each calorimeter and used to
identify and process signal events to build an energy
spectrum; evaluate the energy-dependent detector re-
sponse; and measure related detection efficiencies. Most
recently, this set of analysis techniques has been applied
to the CUORE 2t-yr TeO2 exposure data release (see
Fig. 1).

2 The CUORE experiment

Located at the Gran Sasso National Laboratory in Italy,
CUORE primarily searches for 0788 decay of 1°°Te,
whose signature is a peak at 2527.5 keV [16]. The CUORE
detector consists of 19 towers, each with 13 floors of
2 x 2 calorimeter arrays. By using 988 cryogenic calorime-
ters as particle detectors, CUORE’s active detector mass
of 742kg TeO» simultaneously serves as the source of
13°Te 0v8B decay and the means of detection. In each
CUORE calorimeter, the absorber material is a TeO2
crystal whose temperature is measured by a neutron-
transmutation-doped (NTD) germanium thermistor. Each
crystal is also instrumented with a silicon resistor (heater),
designed to periodically inject a fixed amount of energy
in the detector for thermal gain correction [17]. When
a CUORE crystal is operated at ~10mK, the temper-
ature variation due to energy deposited by a particle
is ~100 wK/MeV and the corresponding voltage drop
across the NTD is ~400V/MeV [11]. The mean rel-
ative energy resolution of the CUORE calorimeters is
~0.3% at Qe [2].

EM Total Exposure Accumulation
[_ [ES Science - First Release (2025)
[ [5] Nature 604, 53-58 (2022)

g
S

TeO, Exposure (kg-yr)

PRL 120, 132501. (2018)
_PRL.124, 122501, (2020)

Dec-2017

Jan-2020 Dec-2021 Jan-2024
Fig. 1: Accumulated TeO2 exposure since the beginning
of data-taking is shown in blue. Cryogenic improve-
ments for the operational stability and detectors opti-
mization were implemented between 2017 and 2018 [18,
19]. From 2019, the experiment has been in stable data
taking at 11-15 mK, with a strikingly high duty cycle
(~90%) for the cryogenic calorimetric technology [20].
TeO exposures after analysis cuts corresponding to
major data releases are also shown in yellow and or-
ange.

2.1 Data taking campaigns

Data collection is based on ~24-hour-long runs. We dis-
tinguish between physics runs, used to perform rare
event searches, and calibration runs, used to calibrate
the energy response of our detectors. These runs are
combined into datasets. A CUORE dataset contains
roughly six weeks of physics runs with a set of cali-
bration runs at the beginning and at the end. Each set
of calibration runs typically lasts five days and is gen-
erally shared between consecutive datasets.

Datasets also include auxiliary measurement types.
To monitor the stability of the NTD resistances over
time, we perform Working Point (WP) measurements.
NPulses measurements, where a scan of the low energy
region is performed by injecting heater pulses of vari-
able amplitude, are used to check the stability of the
trigger thresholds. Test measurements are acquired dur-
ing maintenance and optimization operations to mon-
itor for possible changes in data quality. A pie-chart
with the breakdown of the CUORE run-time is shown
in Fig. 2.

The CUORE data releases are summarized in Ta-
ble 1. Each release included the re-analysis of the pre-
viously available data, since we progressively imple-
mented improvements in the signal triggering and pro-
cessing algorithms. In 2018, between the first two data

0.5 %
21%
72%
11.8 %
HE) Physics (EY Test
[|] Calibration (EE «Down Time
[HS Working Point HE) NPulses

Fig. 2: Breakdown of the CUORE run-time by mea-
surement type since the beginning of stable data-taking
starting in 2019. Down Time corresponds to periods
during which no data is recorded.

releases, the operating temperature was lowered from
15.0mK to 11.8mK to investigate the thermal gain of
the detectors. Since mid-2021, the original CUORE op-
erating temperature was restored. The most recent data
production includes data from May 2017 to April 2023,
for a total of 2t-yr of analyzed exposure in TeOg [1,
21). The current data-taking plan is to reach 3t-yr of
analyzed exposure in TeOg, corresponding to ~1t- yr of
analyzed exposure in 1°°Te, for the 0188 decay search.

Date of Number Exposure Ref.
closing dataset of datasets (kg: yr)

Sep 2017 2 86.3 [22]

Jul 2019 7 372.5 [23]

Dec 2020 15 1038.4 [2]

Apr 2023 28 2039.0 (1]

Table 1: All CUORE data releases start from the
first dataset taken in 2017. For each data release, the
corresponding date of the closing dataset, number of
datasets, analyzed TeO2 exposure, and publication ref-
erence is listed.

2.2 Data acquisition

The CUORE Data Acquisition System (DAQ) fulfills
different purposes: digitizing analog signals from each of
the ~1000 calorimeters, performing the triggering of the
data, and storing the detector configuration parameters
and data. The acquisition software, Apollo [24], is a
custom C++ code based on the ROOT package [25].

The voltage stream from each calorimeter is passed
through an amplification stage and an anti-aliasing Bes-
sel filter stage. It is digitized with a 1 kHz sampling fre-
quency by an 18-bit ADC. The DAQ stores the contin-
uous waveforms from all the detectors for offline anal-
ysis. For online monitoring, the DAQ also applies an
online software trigger (see Sec. 4) to the data stream
for the event construction, where an event is a segment
of a waveform around the trigger. The DAQ associates
each event with a timestamp and the basic information
needed to identify pulses in the data stream.

2.3 Data production and analysis

The CUORE data production consists of a series of dig-
ital signal processing algorithms which allow the trig-
gered waveforms to be converted into a calibrated en-
ergy spectrum. This is done using the Diana software
developed by the CUORE collaboration [26], a modu-
lar C++ custom software, also based on ROOT [25].
By the end of the data production, each triggered ther-
mal pulse is associated with its determined event-based
analysis quantities such as energy and shape parame-
ters, and proximity to other triggered events in space
and time. Given the large number of detectors in CUORE,
manual scrutiny of each analysis step becomes imprac-
tical and error-prone. Automated tools have been de-
veloped to systematically and efficiently cross-check the
data processing.

3 Reducing the noise in CUORE

The signal bandwidth of the CUORE detector out-
put is 0-20Hz. The dominant noise in this bandwith
comes from 4 Pulse Tube cryocoolers (PTs), which cool
down and maintain the 40 K and 4K stages of the cryo-
stat [19]. These PTs introduce vibrational noise be-
tween 0.1—1.5 Hz due to their rotating motor. In par-
ticular, a prominent 1.4-Hz (and harmonics) frequency
is generated by the speed of the rotating motor. To re-
duce the impact of these vibrations, a system to control
individual PT pressure oscillations was developed [13].
Between datasets, the relative phases of the PTs are op-
timized and tuned to the configuration that minimizes
their induced noise.

Software denoising techniques are used to further
suppress PT and seismic noise in our detector mea-
surements. Our denoising algorithm correlates the noise
measured by each calorimeter with the noise measured

by auxiliary devices [27]. These correlations are used to

predict and subtract vibrationally-induced noise from
the continuous CUORE data stream. The auxiliary de-
vices, which include accelerometers, seismometers, and
microphones, are sensitive to external vibrational and
acoustic noise sources in the range of 0.1 Hz~—1kHz;
they are installed in various locations over the cryostat
in the CUORE Faraday room
ments of the environmental noise are digitized with the
same system used for the CUORE detectors.

28] and their measure-

As part of
spectral densities with each auxiliary
calorimeter. The spectral density of the calorimeter is
determined using only its noise events (waveforms with-
out pulses). The auxiliary device terms
include both linear and quadratic signa
in the time domain; the former captures the capacitive
pickup from vibrations in the cabling and the latter is
a proxy for the unipolar heat response
brations in the calorimeters. The product of this vector
and the inverse of the matrix of cross-spectral densities
of all auxiliary device pairs results in a
tion from auxiliary device output to the calorimeter
noise at a particular frequency. The transfer function
for each auxiliary device is convolved with the continu-
ous auxiliary device waveform. The sum of the resulting
convolutions over all auxiliary devices is the predicted
calorimeter noise. The result of subtracting this pre-
dicted noise from the original continuous data in the
time domain is the denoised data.

he algorithm, we create a vector of cross-
levice for each

in the vector

contributions

ue to the vi-

ransfer func-

The denoising algorithm is applied to each calorime-
ter independently for every physics run; this accounts
for daily fluctuations in the noise. Calibration runs,
however, last closer to ~30 hours and have event rates
10—100 times higher than physics runs, resulting in too
few noise events to construct reliable transfer functions
from the calibration data alone. In this case, we av-
erage transfer functions from ~1 week of physics runs
taken immediately before or after the calibration pe-
riod. While this averaging attenuates run-level noise
features, it makes the denoising of calibration data pos-
sible.

Acting as a time-dependent filter, this methoc
moves steady-state noise (e.g., PT noise) as well as

re-

transient noise, such as anthropogenic activity near the
detector. The reduction of the peak amplitudes,
ticularly at ~1.4 Hz and its harmonics, in the denoised
power spectrum (blue) compared to the undenoised po-
wer spectrum (orange) in Fig. 3 demonstrates the effect
of this software technique.

par-

Power (mV?/Hz)
Ss

10°'
102
107

10~*

Undenoised channel, avgRMS 9.2mV
107° ——— Denoised channel, avgRMS 3.47mV

1077 i 1 1
1 10 10°
Frequency (Hz)

Fig. 3: Noise spectral shape of a single channel-datase
(Ch-DS) before and after the denoising using ac-
celerometers and seismometers.

4 Data trigger

In CUORE, three different types of trigger flags are im-
plemented: signal, noise, and pulser [24]. Signal triggers
identify particle-induced pulses, noise triggers identify
potential segments of the data to use for noise stud-
ies, and pulser triggers identify silicon heater-induced
pulses. Each trigger is associated with a 10-s event win-
dow, which begins 3s before the trigger. All three trig-
ger algorithms run in parallel during the data acquisi-
tion. An example of an event window, for each trigger
type, is shown in Fig. 4.

Two types of software triggers are used to identify
signal events, one runs online during the data-taking,
the other runs offline on the continuous data; both em-
ploy calorimeter-dependent thresholds. Typical signal
trigger rates in CUORE are on the order of 1—10mHz
during physics runs, and 50-250 mHz during calibra-
tion runs. To monitor the detector stability and char-
acterize the noise, we force the trigger of random events
every 80s. In most cases, the corresponding triggered
events will contain no physical pulse. Thus, after ex-
cluding event windows coincidentally containing a sig-
nal and/or pulser trigger, the random events can be
used to evaluate the noise (see Sec. 5.2). To generate
fixed thermal energy events for thermal gain studies
(see Sec. 5.3.1), we apply a voltage across the silicon
resistors on the crystal to inject a precise amount of
heat. These events and are flagged with a pulser trig-
ger.

= -2000
iF F Signal
& -2500F
-3000F
-3500F
4000
[eicemsiacaantall
-4500F
z ks Noise
3 4420
% C
s
-4435/-
S iz
Ez i Pulser
8% -3000}-
i} L
wot by
> [
-3500/-
-4000/-
-4500F
0 2 4 6 8 10
Time (s)

Fig. 4: Events flagged by the three trigger types: sig-
nal, noise, and pulser. In general, the signal waveforms
exhibit rise times (from 10-90% of the pulse height) of
50-200 ms and decay times (from 90-30% of the pulse
height) of 500ms~—1s.

4.1 Online derivative trigger

CUORE uses an online trigger to identify particle-induced
pulses over a range of energies during the data-taking.
The purpose of this trigger is to enable low-latency
monitoring of the detector performances and provide a
priori signal and noise information needed by the more
sophisticated offline trigger algorithm (see Sec. 4.2).
The online trigger is integrated in the Apollo software.
The algorithm is a derivative trigger (DT) which fires
whenever the
a given time interval (average), exceeds a threshold for
a specified debounce time. Both average and debounce
intervals are set to 40 ms [24]. An artificial trigger dead
time—i.e., minimum time interval between consecutive

erivative of the waveform, calculated on

triggers in the same calorimeter—is set to 200 ms.

To identify low energy events, the threshold for each
calorimeter is set just above the noise level. Since the
noise varies among the calorimeters, the CUORE thresh-
olds are also calorimeter dependent. We set the trigger
threshold based on the trigger rate on noise events. For
each calorimeter, we first acquire dedicated test runs
where no heat pulses are injected and then apply an of-
fline algorithm that simulates the online Apollo deriva-
tive trigger using different thresholds. After computing
the associated trigger rates, the optimal threshold is
identified as the lowest threshold for which the trig-
ger rate simultaneously is lower than a few mHz and
demonstrates a shallow dependence on the threshold.
The first condition ensures that the DAQ is not over-
whelmed by the incoming trigger rate, while the second
condition mitigates triggers on noise fluctuations.

4.2 Offline Optimum Trigger

The availability of continuous data allows us to digi-
tally re-trigger it at a later time, using different trigger
settings and different triggering algorithms. For the offi-
cial data production, we use the Optimum Trigger (OT)
algorithm [29,30]. The OT is based on the matched fil-
ter technique and uses the expected signal pulse shape
from DT-identified pulses in the denoised data to en-
able significantly lower thresholds with respect to the
online DT. The buffer of the data stream is filtered
with an Optimum Filter (OF) (see Sec. 5.2) in the fre-
quency domain, in order to maximize the signal-to-noise
ratio. Since the signal has a relatively small bandwidth
(<30 Hz), the acquired data are initially passed through
a low-pass Chebyshev filter using a cutoff value of 5% of
the sampling frequency, and then down-sampled from
1 kHz to 125 Hz. This is done to speed up the algorithm
application while keeping the same performance within
the signal bandwidth. Thus, each buffer is filtered with
the OF transfer function, then transformed back to the
time domain, where a trigger threshold is set to 4 times
the noise resolution. The filtered waveforms are less

noisy than the original ones and the baseline fluctu-
ations are reduced. Furthermore, because the filter is
sensitive to the shape of the expected signal, triggers
on spurious noise-induced pulses are suppressed.

5 Thermal pulse amplitude reconstruction

The energy deposited to a calorimeter is correlated to
the resulting pulse amplitude. Thus, amplitude recon-
struction is the precursor to building the energy spec-
trum for our rare event searches. As a first order approx-
imation, the pulse amplitude (A in Eq. 1), can be de-
composed in terms of an energy-dependent term a(£),
where FE is the energy deposited into the crystal and
a temperature-dependent term G(T), which represents
the detector intrinsic gain related to the operating tem-
perature T:

A(E,T) © a(E)- G(T) (2)

Thus, we aim to extract a from our measured value of
A for each pulse. In order to accurately evaluate the
energy-dependent amplitude component of each event,
we first assess the quality of each event pulse (Sec. 5.1),
then construct an OF from a subset of high quality
events and apply the filter to each event (Sec. 5.2), fi-
nally we characterize and remove the temperature de-
pendence from the measured pulse amplitudes (Sec. 5.3).

5.1 Thermal pulse basic parameters

We perform a preliminary processing of the denoised
data to evaluate basic parameters of the event. The
pretrigger, defined as the first 2.25s of each event win-
dow, is used to compute the baseline parameters which
identify the detector conditions before the particle in-
teraction in the detector. The Baseline is calculated as
the average of the pretrigger and is used as a proxy for
the calorimeter temperature at the time of the event.
The pretrigger is fit with a first-order polynomial, and
the slope (BaselineSlope) is used to identify events
overlapping with the decaying tail of an earlier event
in the same calorimeter. A proxy for the raw noise is
given by the BaselineRMS, which is calculated as the
root mean square error of the linear fit used to com-
pute the baseline slope. Pile up events are identified by
the SingleT rigger and NumberO f Pulses parameters,
which track the number of triggers and signal pulses, re-
spectively, within the entire 10-s window. Finally, a sim-
ple estimate of the pulse amplitude (Max Baseline) is
obtained as the raw pulse height relative to the Baseline.
Examples of CUORE pulses and associated basic pa-
rameters are reported in Fig. 5.

5.2 Optimum Filter (OF)

The OF technique [31] is used to obtain a more precise
estimator for the pulse amplitude. The OF is designed
S -6000F .
€ E IsSignal: True
6050 E MaxBaseline: 304.8 mV
2 E Baseline: -6325.3 mV
S -6100F BaselineRMS: 2.9 mV
a FE SingleTrigger: True
~6150F NumberOfPulses: |
-6200-
~6250
6300
-6350
S
& -5950 IsSignal: True
2 MaxBaseline: 221.1 mV
sg 6000 Baseline: -6325.2 mV
£ -6050 BaselineRMS: 2.4 mV
SingleTrigger: False
-6100 NumberOfPulses: 2
-6150
-6200
-6250
-6300
6350 L L L L L
0 2 4 6 8 10

Time (s)

Fig. 5: Example of single pulse and pile-up events. The
variables associated with the main event are listed. The

10-s event window begins ~3s before the main event.

to maximize the signal-to-noise ratio given a known
signal shape and noise power spectrum. The detector
response function s(t) is assumed to be a fixed tem-
plate. Moreover, the stochastic noise on the detector is
assumed to have a stationary behavior in order to be
described by a definite noise function n(t). Thus, the
OF pulse in the frequency domain can be written as

S(w)*

OF (uy ot
Ve) TNE

em Ve) 3)

where V(w) and S(w) are the Fourier transforms of the
signal and the detector response function, respectively;
N(w)|? is the noise power spectral density; w is the fre-
quency; and Tj¢ acts as a phase shift which maximizes
the amplitude of the filtered signal transformed back to
he time domain.

Since each calorimeter i has different characteris-
tics reflected in the pulse shape and noise, both the
response function s;(t) and the noise power spectrum
N;(w)|? must be evaluated for each detector. We use
proxies for building the filter templates: a calorimeter-
dependent averaged pulse (AP) for s;(t) and an aver-
aged noise power spectrum (ANPS) for |.N;(w)|?. Based

AP ANPS
Event Type Signal Noise
SingleTrigger True True
NumberOfPulses 1 0
|BaselineSlope| <0.005 mV/s <0.001 mV/s
Raw amplitude >40-BaselineRMS  <10-BaselineRMS
Data Type Calibration Background

Table 2: List of the event selections for building AP
and ANPS. The Baseline Slope cut for the ANPS is set
over the whole event window, while AP only uses the
pretrigger.

i=}

—— Average Pulse
Filtered Average Pulse

S
oo

2

Amplitude (a.u.)

2
PS

0.0

-0.2

Time (s)

Fig. 6: Example of an average pulse (orange) for a single
Ch-DS. The filtered average pulse (blue) demonstrates
the effect of the OF on the average pulse.

on the first-level analysis (see Sec. 5.1), we apply rel-

evant selection cuts on the pulse parameters to iden-
ify genuine particle signals which are used to build
the AP. In particular, the APs are built from calibra-
ion data given the larger available statistics of signal
pulses across multiple energies. A dedicated selection is
also applied to the noise triggers to identify pure noise
events (waveforms in which no pulses occurs) to build
he ANPS. Table 2 summarizes the selections for build-
ing the AP and ANPS. Examples of a built AP and
ANPS are shown in Fig. 6 and Fig. 7, respectively.

After we construct the calorimeter-dependent fil-
ers, we apply the corresponding filter to each event.
The amplitude of each filtered pulse is determined by
interpolating the data points around the maximum with
a second-order polynomial in order to reduce the dis-
cretization error of the evaluation.

5.3 Thermal gain stabilization

Small variations of the base temperature may change
the calorimeter intrinsic gain, leading to different pulse
amplitudes for events depositing the same energy in a
fo

S
=

ANPS (mV7/Hz)

oo

°
5s

=)
ce

Average Noise PS

10° —— Filtered Average Noise PS

1 1 1 1
10" 1 10 10°
Frequency (Hz)

10-?

Fig. 7: Example of an average noise power spectrum
(orange) for a single Ch-DS. The filtered average noise
power spectrum (blue) demonstrates the effect of the
OF on the frequency components.

given crystal. This degrades the detector energy reso-
lution. Therefore, it is necessary to correct the filtered
pulse amplitude against thermal drifts that occur dur-
ing the data taking. Events depositing the same energy
can be used to trace the evolution of the internal gain
as a function of the crystal temperature. A proxy for
the temperature is the pulse baseline:

b(L) = Vor — Gere - Vout (T) (4)

where Vog and Gee are respectively the offset and gain
from the electronics, and Vout is the NTD output volt-
age. In general, a decrease of the baseline corresponds
to a cooling of the detector, which results in a slightly
higher pulse amplitude since the detector internal gain
increases.

CUORE applies two different techniques for the ther-
mal gain stabilization (TGS): one is heater-based (hea-
ter-TGS) and the other is calibration-based (calibration-
TGS) [26,32,33]. Both approaches are calorimeter de-
pendent. Calibration-TGS was originally developed for
calorimeters with faulty or malfunctioning heaters, but
was also found to improve the performance of a subset
of calorimeters. These calorimeters tend to exhibit dif
ferent trends in their pulse amplitude with temperature
between heater- and particle-induce events. Thus, when
available, both approaches are applied to each calorime-
ter and their relative performance is used for the final
estimator selection (see Sec. 6.2).

5.8.1 Heater-based stabilization

The heater-based stabilization algorithm relies on the

constant voltage signals that are injected into the Si
heaters attached to the crystals [9]. The amplitude of

S Bi = E 7 >
e.28E : im ‘ammitwae | 7504 é
3 2910E tabilizes mp. jitude s| 3
Ss ise at
= 2905E- {5020 =
Eg E 4 &
200 Bd 8, eRe: S Be BPelee-|5000 <
2805- . { 3
2890F {4980 2
E 1. &
2BESE (4960
2880E. 4 ! ! i i a
-5800 -5600 -5400 5200 -5000
Baseline (mV)

Fig. 8: Amplitude of pulser events from two runs for
a single channel before (orange) and after (blue) ther-
mal gain stabilization. The stabilized amplitudes of the
pulser events are set to an arbitrary values of 5000 a.u.

this stabilization pulser is selected such that their re-
constructed energies represent events at Qgg (~3 MeV).
The temperature dependence of the fixed-energy heater
pulse amplitudes is determined by using the correspond-
ing Baseline, b, as a proxy for temperature, T. The
trend of the temperature-dependent term in Eq. 2, G(T),
is parametrized with a first-order polynomial, so the
heater pulse amplitude can be written as

An(T) = an(En) - (po + pi: (2), (5)

where ap, is a constant (since E), is fixed) that is set to
an arbitrary value and po and py; are the fit parameters.
Since G(T) is expected to be the same for both signal
and heater pulses, we apply the following correction to
each event to extract the energy-dependent amplitude
of the signal pulse:

a,(B) = AGT) (6
Po + pi U(T)

where A is the OF-amplitude of the event. This stabi-

lization procedure is performed for each run. Figure 8

shows the original and stabilized amplitude against base-

line for stabilization pulser events for a single calorime-

ter.

5.8.2 Calibration-based stabilization

The calibration-based stabilization algorithm uses the
events in the 7°°T] 2615 keV gamma peak from calibra-
tion data as monoenergetic reference events. Given the
limited statistics of the reference pulses, this procedure
cannot be applied to a single run, but instead must be
applied to the entire dataset. This stabilization algo-
rithm first uses the value of Vog—computed for each
calorimeter from the WP measurement (see Sec. 2.1)
that is measured closest in time—to correct the base-
line of each reference event. Then, for each calorime-
ter, the amplitude of the 2615 keV events as function
of (Gee + Vout) is fit with a quadratic function. Finally,
the pulse amplitudes in the dataset are corrected us-
ing the corresponding calorimeter-dependent function.
Given the potentially larger range of baseline variation
between initial and final calibrations, compared to that
of a single run, this approach accounts for nonlinearities
in the gain temperature dependence.

6 Energy reconstruction

To reconstruct the energy associated with each pulse,
we periodically expose the detector array to gamma
rays of known energies by suspending 7°?Th and °°Co
radioactive sources between the outermost cryostat ves-
sel and external lead shield. For each calorimeter, the
amplitude response from each stabilization is calibrated
against the characteristic energies. To select between
the energy estimators derived from the heater-based
and calibration-based stabilizations for each calorime-
ter, we compare their ?°°T] 2615 keV peaks.

6.1 Energy calibration

To convert the stabilized pulse amplitudes to energies,
we histogram the amplitudes and fit the position of
the peaks in the spectrum. Depending on the acquired
statistics, we fit 2—4 peaks for each calorimeter. Among
the peaks in the spectrum, the algorithm identifies the
highest amplitude peak with the best signal-to-noise ra-
tio as the reference peak. The other calibration peaks
are identified by considering their relative positions to
the reference peak. We fit two models to each peak.
The first model consists of a Gaussian function, while
the second model consists of a Crystal Ball function; in

both models, we overlap a background contribution—
the sum of a first-order polynomial and an error func-
ion (Compton edge component). To facilitate the fit
of the latter, the Gaussian fit parameter results from
the former are used to seed the parameters (mean and
width) of the Crystal Ball. We compare the results of
both fits and then choose the better performing one
for each peak based on convergence and goodness-of-
fit. After selecting the model for each peal

, we corre-

ate their positions against the calibration gamma-ray

energies with a second-order polynomial with zero inter-

cept. All calibration peaks, including the reference peak
corresponding to the ?°ST] gamma line at 2615keV,
are labeled for a representative CUORE spectrum in
Fig. 9. This calibration procedure is performed for each

S
2]

et+e7 2087}

Counts/keV
S
<

&,

10°

L
2500 3000
Energy (keV)

L L L L
0 500 1000 1500 2000

Fig. 9: Cumulative Th-Co energy calibrated spectrum
for a single dataset using the heater-based thermal gain
stabilization technique. The peaks used to calibrate
the spectrum are at 510.999 keV (e++e7), 1173.240 keV
(Co), 1332.508 keV (°°Co), and 2614.511 keV (?°TI).
The other peaks in the spectrum are not used for cal-
ibration due to their low statistics in individual detec-
tors.

stabilization method available for each calorimeter and
dataset.
To guarantee the fit performance of most calorime-
ters, we flag calorimeters for manual seeding of the peak
positions if any of the following conditions apply:

— the number of events in the calibration spectrum
does not meet a set threshold

the algorithm fails to identify the reference peak
the algorithm fails to identify or fit one or more of
the non-reference peaks

the algorithm fails to fit both models to the refer-
ence peak
the fit for the calibration function fails

For these calorimeters, we then repeat the calibration(s).

6.2 Energy-estimator selection

When available, we select between the two energy esti-
mators by calculating a figure-of-merit (FOM) for each
and taking their ratio:

The numerator and denominator in Eq. 7 correspond to
the heater-based (h) FOM and the calibration-based (c)
FOM, respectively, where C and @ are the fitted integral
and standard deviation of the 2615 keV peak. We eval-
uate the Fisher test statistic, F(a) for (C — 1) degrees
of freedom, where a is the significance level—i.e., the
10

probability that an F-value will be larger than the F(a).
When W < land W > F(a), the calibration-based en-
ergy estimator is selected, otherwise the heater-based
energy estimator is selected. For a typical dataset, when
using a = 0.20, this method selects the calibration-based
energy estimator for ~100 calorimeters. This value of
a@ was chosen based on the performance of a subset of
datasets.

6.3 Energy thresholds

To evaluate the trigger threshold and the trigger effi-
ciency curve, we use a software procedure to generate
and inject simulated pulses of various energies into the
data stream. For each CUORE run and each calorime-
ter, we revert the injected pulse energy to a stabilized
pulse amplitude and eventually to a raw pulse ampli-
tude using the calibration (from Sec. 6.1) and stabi-
lization (from Sec. 5.3) coefficients calculated in previ-
ous steps of the data analysis. We then scale the cor-
responding average pulse to match the raw amplitude
value and overlap it with a random noise waveform,
characteristic of the given calorimeter for the dataset
under analysis. This emulates a real pulse correspond-
ing to the desired energy. For each calorimeter, we vary
the energy of the injected pulses and estimate the trig-
ger efficiency as the ratio of the number of OT triggered
events (Sec. 5.2) to the number of injected ones. The
event is considered if an OT trigger is found within a
time interval corresponding to the width at half maxi-
mum of its AP. We fit the efficiency of the OT trigger as
a function of the pulse energy using an error function.
Then we invert the relation to determine the energy
threshold as the energy at which the efficiency function
reaches 90% [34].

6.4 Recovery of saturated pulses

The CUORE analog electronics boards are saturated
for detector voltages |Vou,| > 9-2V, corresponding to
energies above ~15 MeV [35]. To reconstruct the en-
ergy of these saturated events for physics analyses at
high energies—e.g., the study of the muon spectrum,
the search of events induced by neutron captures, or
the search for tri-nucleon decay—we utilize a “time-
above-threshold” metric. With this method, we first
consider unsaturated pulses with known energies and
for each, measure the time interval (tabove) that the
pulse exceeds a given threshold voltage (Vinresh). We
then use the relation between tabove and h/E, where
h = Vinresh — Baseline is the pulse height and FE is
the energy of the pulse, to determine the energy of the

saturated pulse. Assuming pulse linearity, for a pulse
saturating at Vsat, we extrapolate its energy to

Veat — Baselinegat

Esat = (8)

* (tabove = teat)

where the denominator is h/E evaluated at tsat, the
time interval above the saturation threshold, Vgat.

7 Reconstruction of multi-site events

From our Monte Carlo simulations of CUORE, the prob-
ability for full absorption of a hypothetical 01,33 decay
in the same crystal of origin is ~88% [36]. Thus, we can
leverage the single-site nature of 0vG6 decay to mitigate
the background by using an anticoincidence cut to fil-
ter away events that occur within a given time interval
of another event belonging to a different calorimeter in
the detector array. The time interval for the cut, called
the coincidence window, is chosen to be wider than the
characteristic time resolution of the CUORE calorime-
ters in order to efficiently identify multi-site events, but
also narrow enough to reduce the rate of random co-
incidences. This cut primarily rejects a decays that
occur on the crystal surfaces, y rays that scatter in
one calorimeter before being absorbed in another, cas-
cade 7 rays from radioactive decays, and muons passing
through the tower(s) along with their secondary neu-
trons. Thus, we categorize events by their multiplicity,
M, defined as the number of triggered pulses within the
coincidence window, At*.

7.1 Time response synchronization

A true physical coincidence among different calorime-
ers originates from a particle passing through and de-
positing energy in more than one crystal, or from mul-
tiple particles emitted simultaneously from the same
radioactive decay depositing energy in different crys-
als. In both cases, the time difference (At) between
the energy depositions is negligible with respect to the
intrinsic pulse rise time of the calorimeter. When de-
ermining M, we specify both the coincidence window,
At*, and a minimum energy deposition for all calorime-
ers involved.

To optimize At*, we first identify preliminary M = 2
events that occur within 500 ms of each other, where
each event in the multiplet deposits an energy above
30 keV, and with both energies summing to ~2615 keV.
This ensures most events in the distribution correspond
to true physical coincidences. As demonstrated in Fig. 10
(in orange), the distribution of At for these M2 events
11

5
Ss

— Synchronized timing

Sy
i=}

—— Raw timing

Counts/0.5 ms
ge 8
opt

a
=]

40

-0.100 -0.075 -0.050 -0.025 -0.000 0.025 0.050 0.075 0.100
t (s)

Fig. 10: Distribution of At for double coincidence
(M= 2) events where the energies released in the two
calorimeters sum to ~2615 keV. The distribution is ob-
tained from calibration data of a single dataset and it
is shown before (orange) and after (blue) the time re-
sponse synchronization.

has a broad distribution, which also features fine struc-
tures. These structures are attributed to the character-
istic rise time of individual calorimeters, which varies
between 50—200 ms, depending on the operational tem-
perature of the detectors. For example, a simultaneous
energy deposition in two calorimeters gives rise to a pair
of events that have a characteristic time difference that
is attributed to their different rise times. We refer to
this characteristic time difference as the delay between
the two calorimeters.

To obtain a more precise At among coincident events,
we synchronize all calorimeters by correcting for the
delay; this allows us to use a narrower At*. We use
wo different methods for calculating the delay. The
primary method uses coincident events, while the sec-
ondary method is used for designated reference calorime-
ers, or when the primary method is unavailable due
to low statistics. Both methods are applied on a tower
asis, with each tower having a designated reference
calorimeter. All towers are then synchronized with re-
spect to an overall reference calorimeter.

Using calibration data for high statistics, we iden-
ify M=2 events where the total energy deposited is
2615 + 25keV. For adjacent calorimeter pairs, the first
method calculates their relative delay by averaging the
At of their multiplets. Instead of using physical coin-
cidences, the second method uses pulser events to pro-
vide high-statistics sets of synchronized pulses. For each
pulser event, an associated rise time is calculated as the
time difference between the trigger position and the

maximum of the waveform, as computed by the Op-
timum Filter (see Sec. 5.2). For each calorimeter, the

mean rise time of its pulser events is then used as a
proxy for its characteristic rise time. Thus, the relative
delay between calorimeter pairs is calculated as the dif-
ference between their rise time proxies. If necessary, this
method can be used for non-adjacent calorimeter pairs.

After calculating all possible relative delays in the
tower, we calculate the absolute delay. Within a tower,
the absolute delay of a calorimeter is calculated by sum-
ming the relative delays along the path of adjacent
calorimeters, to the reference calorimeter, that mini-
mizes the uncertainty on the absolute delay. We finally
synchronize each CUORE calorimeter with respect to
the designated overall reference calorimeter by sum-
ming its absolute delay, rise time proxy of its reference
calorimeter, and, if in another tower compared to the
overall reference calorimeter, the rise time proxy of the
overall reference calorimeter. The effect of the time re-
sponse synchronization on the At distribution of phys-
ical coincidences is demonstrated in Fig. 10; the time
synchronized distribution (in blue) is the basis for using
At* = 10 ms for the 0v6 decay analysis.

7.2 Coincidence data

For each event in a given multiplet, we compute and

store the associated coincidence data:

— multiplicity

— DAQ channel number associated with the calorime-
ter

— synchronized time stamp

— energy

— total energy from summing the energy of all events
in the multiplet

— index indicating the time ordering

Coincidence events can be reconstructed in different
ways, and depending on the physics process we are in-
vestigating, a fine-tuning of the coincidence parameters
might be necessary. In addition to the coincidence win-
dow, At*, parameters and options that can be applied
to the coincidence algorithm that builds the multiplets
include:

— Energy threshold: the minimum energy an event must
have to be considered for coincidence tagging. This
can be tuned for each calorimeter, for example set-
ting it to the OT threshold computed as described
in Sec. 6.3;

— Running window: if this option is selected, the co-
incidence window will open at the first event in the
multiplet and close when there are no more events
within time At* of the last event. In this case the

effective coincidence window can become arbitrarily
long.
12

— Distance cut: the distance between triggered calorime-
ters represents an effective way to reduce inefficien-
cies due to accidental coincidences; it is unlikely that
two simultaneous events that happen far apart are
causally related. Two events, where one deposits en-
ergy in calorimeter a and the other deposits energy
in calorimeter b will be considered coincident if

(Atay < At*) & (Rab < Rimax)

where R,» is the distance between the centers of
the corresponding crystals and Rmaz is the value of
the distance cut. The distance between any pair of
CUORE crystal centers ranges between 60— 1020 mm.

— Running radius: as in the case of the running win-
dow, if this option is selected, the coincidence win-
dow will open at the first event in the multiplet and
close when there are no more events within distance
Rmax from any event in the multiplet.

The value of the energy threshold for coincidence tag-
ging is usually set to 40keV for physics analyses such
as the Te 0188 decay search or the CUORE back-
ground model (BM). For both these studies, we are
mostly interested in the energy region above 100 keV
and we aim to reduce the rate of accidental coincidences
in high rate calorimeters by setting a threshold. Conse-
quently, we use a coincidence window of 10 ms (+5 ms)
for the 0v86 decay analysis, while a wider coincidence
window of 60 ms (+30 ms) is used for the BM analysis
and in general whenever there is the need to accurately
calculate coincidences over a large energy range, from
the gamma region (below 3 MeV) to the alpha region.
The
us to implement a 10-ms coincidence window; it is opti-

ime synchronization described in Sec. 7.1 allows

mized using M = 2 coincidence events with total energy
deposited by the multiplet ~ 2615 keV, which is close
to Qgg. A wider coincidence window is chosen for the
BM analysis since we observe that the shape of the fil-
tered pulse has a residual dependence on energy at the
edges of the energy range of interest—i.e., for nuclear
recoils and a particles—so by enlarging the coincidence

window, we can safely neglect this dependence over a
broad energy range. At the same time, the running win-
dow option is not selected for the BM analysis and only
used for the 0v86 decay analysis, while the running ra-

dius option is always applied with Rmax = 150mm,
which is related to the distance between two crystals
facing each other across adjacent towers. Finally, the
low energy analyses, which search for dark matter and
axions, and focus on the energy region below 100keV,
exploit the feature of calorimeter-dependent thresholds
for the identification of coincident events.

3
&
5
BE
a iF
310k 9
 10'E. . UR
FE oO: =
i ibaa L 1 1 L L 1
0 1000 2000 3000 4000 5000 6000 7000

Energy (keV)

Fig. 11: Reconstruction error of M=1 events tha
passed basic quality cuts for a single Ch-DS. The blue
circle indicates the data point associated with the ac-
cepted pulse shown in Fig. 12 (top). The orange circle
indicates the data point associated with the rejected

pulse shown in Fig. 12 (bottom).

8 Pulse shape analysis

To further reduce the background, we perform pulse
shape discrimination (PSD) to identify and remove even-
ts associated with pulse shapes that are atypical com-
pared to particle-induced events and thus more likely
induced by unphysical events.

The Reconstruction Error method is used to dis-
criminate between physical and non-physical (pileup,
noise, etc.) events. This method compares each event
(v) with an average pulse (vp) that is representative
of a particle-induced pulse in an energy range between
~100 keV and ~2615 keV [37]. We calculate the Recon-
struction Error (RE) as

DB 2
RE= [va —(v- vap)varal ; (9)
d=1

where d is the sample index in the waveform. In this
form, the RE quantifies the difference in pulse shape
between a signal-triggered event and its corresponding
average pulse. Figure 11 shows the reconstruction er-
rors of M=1 events that passed basic quality cuts. The
lower diagonal band represents signal-like events, which
distinctly include physical alpha events from !°°Pt and
210Po above 3 MeV. A pulse corresponding to an event.
inside and outside the signal-like band is shown at the
top and bottom of Fig. 12, respectively.

We normalize the RE distribution by fitting the
signal-like band with a second-order polynomial f(£),
and computing the median absolute deviation (MAD)
with respect to the best-fit curve. The normalized re-

13

~ c Zu4t
z L Accepted os C
g 35007 yok
s E E
> [ Lob
-4000F-
[ 08
~4500- 0.6 ——— (2478 - 2490) keV + (2540 - 2578) keV
E C —— (2700-3100) keV
0.4;—
> : ‘ ——— (2700 - 3100) keV + (3500 — 3900) keV
6 bs Rejected cy ! ! ! !
> -3500- 0 5 10 15 20
Ey [ NRE
2 [
r Fig. 13: FOMpsp optimization curves from combin-
-4000;- : : a :
L ing two datasets based on the selection efficiency in
[ the 2615keV peak, €, and the selection efficiency in
4500\- the background region, €pxg. The background region(s)
+ used to calculate ekg are indicated in the legend. Only
1 1 1 ! L the orange curve is used to decide the NRE thresh-
0 2 4 6 8 1 old, however we present the blue and yellow curves to
Time (s)

Fig. 12: Top: Example of an accepted pulse with
2615 keV energy and RE=6328a.u. (NRE=3.6 a.u.).
Bottom: Example of a rejected pulse with 2847 keV en-
ergy and RE= 124817 a.u. (NRE = 228.4a.u.).

construction error (NRE) is then defined as

RE — f(£)

NRE = Sane

(10)

In order to select good quality physics pulses, we
apply a cut on the NRE value. We identify the NRE
threshold empirically by optimizing the following figure
of merit:

FOMpsp = —

ie (11)
where € (€pkg) is the efficiency of accepting signal (back-
ground) events within a predefined energy region, taken
as 2615+10keV (2700—3100keV). In order to avoid
biasing our decision on the upper NRE threshold, for
each dataset, the FOMpsp is calculated using half of
the data, selected at random. Based on this procedure,
we set an NRE threshold of 10 for all calorimeters across
all datasets. Figure 13 demonstrates the typical trend

of the FOMpgp as a function of the normalized recon-
struction error cut value.

9 Blinding

A data salting procedure, which consists of inserting
an artificial peak at Qgg, is applied to the 0v86 de-

show that using alternative backgroun
would yield the same result.

regions for €pkg

cay region of interest (ROI). This peak is constructed
by exchanging a random fraction (10—12.5%) of events
between the 2615keV peak and the posited Qgg. The
chosen fraction range ensures the fake peak in the data
would camouflage a potential true signal peak, whose
amplitude cannot be greater than the limit from the
previous Te-based experiments. Specifically, events within
+50keV of either energy are randomly shifted by the
ifference between the two peak energies, |E(?°°T1) —
Qga|. Figure 14 shows a comparison of the blinded and
unblinded 0v88 dece
range. A similar data salting procedure is applied in
other peak-searches, such as 0788 decay of !°°Te [38]
or °Te [39], to blind their respective ROIs.

spectra in the relevant energy

10 Detector energy response for 0v3G decay

In order to search for the potential 0v86 decay signal in
the data, we model the ROI as a flat background with
peaks at the posited Qgg value and Co sum peak en-
ergy, where the latter originates from the simultaneous
deposition of two ®°Co gamma rays (at 1173 keV and
1332keV) in the same crystal. This section describes
our peak shape characterization and the evaluation of
the detector energy response in the 0v88 decay ROI.
Specifically, we determine the energy-dependent reso-
lution and energy bias, where the latter is defined as
the difference between the measured peak position and

a

3 iB
$ 1400— —— Unblinded
5 Fo seesee Blinded
§ 1200F-
1000F-
800
600
400
200F
of eee alles pera pene
2500 2550 2600 2650 2700
Energy (keV)

Fig. 14: Comparison of blinded (salted peak at Qa)
and unblinded spectra for the total 2t-yr data release
after all 0vG6 decay analysis cuts.

nominal characteristic gamma-ray energy, and extrapo-
ate them to Qgg for each dataset and active calorime-
er.

0.1 Lineshape

The general peak shape, interchangeably described as
ineshape, is modeled after the ?°°T] 2615 keV photo-
eak from calibration data for each Ch-DS. We use cal-
ibration data instead of physics data to ensure high
statistics and reliable detector response fit parameters
‘or most Ch-DS pairs.

Our phenomenological lineshape model of a photo-
eak consists of a sum of up to 3 Gaussians—a main
Gaussian and two lateral Gaussian sub-peaks positioned
at the left (L) and the right (R) of the main one—all
sharing the same width [1]:

feat(E3 He, Ce, AL, AR, GL, 4R) =
G(E; be, Gc) + ALG(E; at Me, Fc) + ARG(E; arpe; Fe)
1+A,+Apr

(12)

where G(E;,1.,0.) indicates the main Gaussian func-
tion centered at jz. with standard deviation o., while
Az;r and az; scale the amplitudes and positions of
the Gaussian sub-peaks, respectively. We perform the
fit with a series of iterations, setting App = 0 in cases
where App < 10° and broadening the fit parameter
ranges in cases of railing.

The lineshape model adapts to the ?°°T] 2615 keV
calibration photopeak, however, to properly account for
the features of the calibration spectrum between 2530—
2720 keV, we also include the following components in
the fit model [26,37]:

3c
g 3b 1 t
> +
2
g
z
g
Ss]
+
1
©,
-1 1 1 Fi 1 fs 1 ian ‘1 i ri 1
10" 3340 2560 2580 2600 2620 2640 3660 2680 2700 2720
Reconstructed Energy (keV)
Fig. 15: Top: Ratio between calibration data and peak

shape model. Bottom: Summed fit result of the ?°8T]

peak in calibration data for a single tower-dataset. We
label the different fit components: (a) ?°°T] photopeak,
(b) multi-Compton continuum, (c) 2615keV y with
130Te X-ray escape, (d) 2615keV y and 1°°Te X-ray
coincidence (e) 2615 keV and 7ST] 583keV + coin-
cidence with e+/e~ 511keV escape, and (f) uniform
background. This figure was adapted from [1].

— a continuum that extends into the left side of the
eak and is due to 2615keV ys undergoing multi-
Compton scattering
— a peak at 2585 keV resulting from the photo-absor-
tion of a 2615keV 7 followed by the escape of
a °Te X-ray whose energy ranges between 27-
31 keV
— the coincidence of a 2615 keV y and a }°°Te X-ray
—a peak at 2687keV due to the summed energy of
208T] 583keV + 2615 keV ys followed by a e+/e~
(annihilation) 511 keV escape
— a flat background

While the lineshape parameters of the photopeak are
defined at a Ch-DS level, due to limited statistics, we
define the parameters to characterize the additional
spectral features at tower-dataset level and perform the
fit simultaneously over all calorimeters in a given tower-
dataset. Figure 15 shows a composite fit for a single
tower-dataset. With respect to this procedure, on aver-
age we exclude ~60 calorimeters per dataset from this
and further analysis steps due to poor statistics.

10.2 Energy scaling

We use physics data to determine the energy depen-
dence of the lineshape parameters, 0 and js, for each
Ch-DS. Due to the limited statistics, we fit the spec-
trum of each dataset, summed over all channels. We
assume that the resolution term can be described as
the quadrature sum of an energy-dependent term, op,
15

and an energy-independent term, oo, that depends on
the intrinsic features of the detectors:

o(E) = V(x)? + (90)? (13)

and that the energy-dependent term scales across phy-
sics data in a way that is proportional to calibration
data. Thus, in physics data we model the energy res-
olution, op, of a given peak at nominal energy E as

op(E) = [02 + Ro(E) - (0? — 02.) (14)

where op,o (¢,0) is the baseline resolution extracted
using noise events on a Ch-DS basis in physics (calibra-
tion) data and R,(£) is a dataset-level fit parameter
that completely isolates the energy dependence. The
peak position, jp, is parameterized as

Hp(E) = R,(£)-B (15)

where R,, is a dataset-level fit parameter. For each peak,
the relative amplitudes and relative positions of the
Gaussian subpeak(s) of each Ch-DS are fixed to the
values extracted from the calibration fit.

Source Q-value (keV)

2087] 2614.5
a0K 1460.8
22h NG 911.2
2148; 1120.3
69Co 1173.2
6°Co 1332.5
214 Bi 1238.1
214 Bi 1764.5
214 Bi 2204.0
2087] 583.2
214 Bi 1729.6
228A 338.3
228 Ke 969.0
212Pb 238.6
228: AG 1588.1
212 Bi 727.3
54Mn 834.8
214 Bi 2447.9
125mTe 144.8
214PpH 351.9

Table 3: Subset of characteristic gamma lines in physics
data identified by our background model.

Table 3 lists the peaks we consider in order to deter-
mine R,(£) and R,,(£). Among them, we select peak
fits with adequate statistics and reasonable convergence
and use them to evaluate the energy dependence of the
detector response. From the selected subset of peaks, for
each dataset, we fit R,(E) to a phenomenological func-
tion that trends as a quadratic polynomial near Qga,

using the BAT [40] package. This function is forced to
zero at low energies to avoid unphysical, negative val-
ues; at higher energies, R,(Z) is quadratic. To tran-
sition between the two energy regions, a sigmoid-like
rolling function centered at ~1000 keV is used; the full
fit function is shown in Fig. 16. The marginalized poste-
rior distribution for R, from each dataset is then used
as a prior in the 0v88 decay ROI fit. This allows us to
maintain a reasonable number of parameters in our fit.
The inset of Fig. 16 shows the marginalized posterior
for R, at Qgg for a single dataset.
We fit the bias on the peak position, defined as

A(B) = p(B) - B (16)

to a quadratic polynomial in BAT. Figure 17 shows
the energy dependence of the energy bias for a single
dataset. The inset of Fig. 17 shows the corresponding
marginalized posterior for the bias at Qgg for the same
dataset. When fitting the ROI, we model the expected
position of the 0788 decay peak in our data for a given
Ch-DS as

Qrit = Selby 208 + A(Qagzg). (17)
In the first term, the ratio is between the measured
peak position (y.) from Eq. 12 and its nominal value,
while Qgg is a global floating parameter which is sam-
pled from a Gaussian prior probability distribution for
Qga; the ratio is used to compensate for any possible
misconstruction of the peak position from the Ch-DS
dependent calibration fit at 2615 keV. The second term
is a dataset- and channel-dependent floating parame-
ter that accounts for the energy bias determined from
the physics data. Namely, A(Qgg) is a random sample
from the multivariate prior probability distribution for

the energy bias at Qgg.

11 Exposure and efficiency

The exposure is a crucial parameter that is used to
quantify the experimental sensitivity—the potential to
detect rare interactions. This quantity is typically de-
fined as the product of the active mass of the detector
and the time over which data used for the search is
collected. From the collected exposure, we identify and
remove data unsuitable for analysis and distinguish the
remaining data as the analyzed exposure. In our analy-
sis, there are two main categories of quality cuts: time-
based cuts and event-based cuts. The former impact the
final value of the exposure (see Sec. 11.3), while the lat-
ter are used in our selection efficiency evaluations (see
Sec. 11.4—Sec. 11.6).
Probability Di

06°08 10 12 14 16
RQ.)

7

@ Data
— Fit
Blo
Hi2c6
00 EBo
popitiiiritiiiritiiiritipviitiiiitins
0 500 1000 1500 2000 2500 3000
Energy (keV)

Fig. 16: Single dataset fit of the energy-dependen
resolution scaling term R, from physics data. Inset:
Marginalized posterior for R,(Qgg) for the correspond-
ing dataset.

(keV)

@ Data

— Fit

Milo

“10-0500 05 10 mo

Q,) eV) M30
Eeraitieiiritiiviitiiritiriitiiiritiny

0 500 1000 1500 2000 2500 3000
Energy (keV)

Fig. 17: Single dataset fit of the energy bias A. Inset:
Marginalized posterior for the energy bias at Qgg for
the corresponding dataset.

11.1 Time-based cuts

At the beginning of the data production, it is necessary
to identify and reject bad intervals, which flag time peri-
ods when the entire detector or a subset of calorimeters
experience disturbances in the data taking conditions.
These calorimeter-intervals are excluded from the anal-
ysis since they may not be representative of the be-
havior of the calorimeter(s) over the dataset. This is
performed manually on the CUORE Online Run Con-
trol (CORC) system, a diagnostic system developed to
monitor all calorimeters by providing an overview of
their performance over time.

Bad for analysis is another type of flag that is used
to indicate that data processing cannot proceed. For ex-
ample, the initial and final few tens of seconds of each

run are flagged since denoising cannot reliably be ap-
plied. Calorimeters are cut from the entire dataset when
sequences fail to compute the parameters necessary for
the analysis—e.g., parameters from stabilization, cali-
bration, lineshape.

11.2 Pulser crosstalk exposure correction

In CUORE, heater events are driven by a pulser board
injecting signals on a set of detector columns at the
same time [9]. Due to electrical interference, this can in-
duce crosstalk pulses in other detector channels outside
of the expected set. Channels affected by this issue are
effectively blind to good physics data when a crosstalk
pulse is present. We exploit the known periodicity of
the pulser cycle to quantify the extent of crosstalk and
calculate a corresponding exposure correction.

This statistical analysis relies on three samples of
events: pulser events, all signal events, and good sig-
nal events—selected after basic quality cuts. For each
calorimeter, using the synchronized pulser trigger times,
we consider the distribution of events within a time

window that spans the pulser trigger, and another time
window that is generally free of crosstalk. The former
is the crosstalk window, taken as +1 second of the

pulser firing time, while the latter is the control win-
dow, taken as a 1 second interval preceding the crosstalk
window. For each calorimeter, we use the all signal
events in the control window to estimate the expected
signal events, Neontrot. The good signal events in the
crosstalk window are used to estimate the number of
events tagged as good pulses (njag). This sample in-
cludes both crosstalk events and particle pulses, so the
probability of a crosstalk event occurring from a given
pulser column firing, P,,eo1 can be expressed as

Ntag — Neontrol
P2,col = = (18)
NPulserCycles

where NpulserCycles is the number of pulser cycles con-
sidered. The impact of the pulser crosstalk on the total
exposure of a given channel, Ccn,tot, is the ratio of the
corrected and total exposures:

fp = BS = FY Prat lea (19)

Ceh,tot a
where Tp is the period for firing on all detector columns,
dtcot is the time interval for firing subsequent sets of
columns, and the summation is over all the CUORE
tower columns. For any given dataset, only ~20 chan-
nels are significantly affected by the pulser crosstalk in
their exposure with f, > 10%.
17

e E
ae ia °
Se + O69
2 7 ° °
2 gor P00 ° 5 eee
i oe a 2 2 o ae 88,
L ? ° °
60/- 8
EL °
r 8
40h °
rt ° © Collected (raw)
L © Analyzed
20;- 8
ea OOD
0 5. 10 15 20 25 30

Dataset Number

Fig. 18: Raw exposure collected and exposure after
analysis cuts (analyzed exposure) for each dataset in-
cluded in the 2t-yr data release.

11.3 Collected and analyzed exposure

The data quality selections, signal processing and ana
ysis chain, in particular the bad intervals and bad anal!
ysis flags, reduce the collected exposure by ~9%, while
the pulser crosstalk has an additional ~1% effect. For a
total collected exposure of 2264.32 kg - yr, the final ana
ysis exposure is 2039.0 kg - yr of TeOg [1]. In Fig. 18, th
collected and analyzed exposures for each dataset ar
reported. The average collected exposure across datase
is ~80kg- yr; dataset number 5 has a much lower expo
sure due to cryogenic issues that cause
of the data-taking. The exposure loss after the analysis
cuts among datasets ranges between 6-15%.

To calculate the exposure, ¢, in the °Te isotope,
we consider its isotopic abundance and the fraction of
the mass of °Te in the TeOz crystals:

m.m.(TeO2)
mm. (20Te) X 30Te

an

an earlier stop

Gaon = Greo, x (20)
where m.m.(TeO2) = 159.6 g-mol~! and m.m.(#9°Te) =
129.9 g-mol! are the molar masses of TeO2 and 1°°Te
compounds, respectively, and mop. = 34.167% is the
natural abundance of !2°Te. Therefore, the final anal-
ysis exposure in TeOy corresponds to 567.0kg-yr in
130Te,

11.4 Base cuts efficiency

The goal of the basic data quality cuts is to reject spu-
rious events (baseline instabilities, noisy events, elec-
tric spikes, pileup events, etc.), while accepting pure
single-site signal events. The efficiencies of these cuts
are measured using heater pulses of known amplitude.

The pulser-based base cuts efficiencies consist of three
terms: detection, pileup rejection, and energy recon-
struction.

11.4.1 Detection efficiency

The detection efficiency €p-; measures the efficiency of
the triggering algorithm. Every time a heater injects a
given amount of power, a dedicated pulser flag is as-
sociated with the event; simultaneously, the triggering
algorithm runs over the waveforms. The efficiency is
evaluated as the ratio of the number of pulser events
that are recognized by the trigger algorithm Nzprs fo)
the total number of injected pulser signals Np:

Ng"9
Np

Det =

11.4.2 Pileup rejection efficiency

The pileup rejection efficiency epy measures the effi-
ciency of discriminating events that exhibit pileup, or
two or more events occurring in the same 10-s event
window. These can be multiple signal events or over-
lapping signal and heater events. The probability of not
having a particle event with pile-up on the main pulse is
related to two individual probabilities: the probability
that, within the event window

— there is no second signal, and
— there is no heater pulse.
So the pileup rejection efficiency can be expressed as
the product of two terms:
NEranoPilep (Tp —w)
x
NE Te

(22)

€Pu

The first term indicates the number of triggered pulser
events that are identified as single pulses. The second
term is the probability that a pulser will not be injected
into a signal event window; this depends on the size of
the event window (w = 10s) and the pulser firing period
(Tp). Meanwhile, the probability of not having a pulser
signal simultaneously with a particle event signal, when
w < Tp, can be approximated as

P(noPulser|IsSignal) ~ 1— bi
Tp

(23)

11.4.3 Energy reconstruction efficiency

The energy reconstruction efficiency €gnrec Measures
the efficiency of events being reconstructed with the
correct energy, based on the energy reconstruction of
pulser events with known energy. For a given pulser
18

amplitude, events which are reconstructed with an en-
ergy within 30 of the mean are identified as well recon-
structed. The ratio of these events to the total number
of events in a window of [mean + 10] is then taken as
the efficiency of the energy reconstruction:

30
Np

€EnRec = Nive (24)
The 100 window was chosen in order to avoid count-
ing pulser events in which, due to the energy sequence
failures, the energy is either reconstructed at zero or at

the default value for the energy variable.

11.4.4 Combined base cuts efficiencies

The three base cuts selection efficiencies described above
are calculated for each channel-run (see Fig. 19). Then
for each of the three base cuts, the DS-Ch efficiency is
calculated as

€BC,DS—Ch = Sota! pe + nfait)

run run

(25)

where Npass and Nai, are the number of pulser events
that pass and fail the base cut as previously defined,
respectively. The dataset efficiency for each base cut is
calculated by averaging over all channels with active
heaters, weighting by exposure (see Fig. 20). In gen-
eral, the detection and energy reconstruction efficien-
cies for pulses in the 0v8G decay ROT are nearly 100%.
The pileup rejection efficiency is slightly lower, ~96%,
with mild variation along the datasets for a given chan-
nel, and among the datasets for the whole group of
channels. This is related to variations of the noise with
time. To evaluate a single base cut efficiency for the
dataset, these three efficiencies are combined numeri-
cally. Namely, we construct a distribution for each one
by using their mean and standard deviation, then take a
random sample of each distribution and calculate their
product. We build a probability distribution for the fi-
nal base cut efficiency from these products.

11.5 Anti-coincidence efficiency

The anti-coincidence (AC) efficiency is calculated from
the physics data after applying the basic quality cuts.
We calculate this dataset-dependent efficiency as
EAC = Npass/(Npass + MFait) (26)
where Npass and Nfai are the number of events above
background in the 1461 keV *°K 7 peak signal region
that pass and fail the M=1 cut, respectively. We use
the °K y peak because it is not associated with a

>
2 1.00;/— 9 9 PP Pee si
e | li Hig a
eal L
at |
0.95;—
0.90/-
0.85|-
im Detection
L Energy Reconstruction
r Pileup Rejection
0.80}—
o_o oe Poy yay Py yt

1 1
351660 351670 351680 351690

Run Number

Fig. 19: Base cuts efficiencies for a single Ch-DS over
sequential physics runs in a single dataset.

F190 e000000000000090000000000000
By
Pat oe
O09 > &
0.98
EC ee
0.97 a tig * 8 oe eho, o**
0.96E ee5e 200°
0.95
& Detection
0.94 Energy Reconstruction
° & _ Pileup Rejection
L ! ! ! !
5 10 15 20 25

Dataset Number

Fig. 20: Base cuts efficiencies averaged over the heater-
active channels for the datasets included in the 2t- yr
data release. Note that the error bars are small and in-
side the open circle markers. The relatively lower pileup
rejection efficiency of the first dataset is a consequence
of the shorter pulser firing period that was initially
used.

gamma cascade, ensuring that the events in the M>1
spectrum are due to accidental coincidences.

To evaluate the efficiency, we perform a counting
analysis in the °K peak region, assuming a Poisson
distribution for the number of counts in the signal re-
gion and background side bands:

Le = J]

i=l,cr

era
1. 27
nj! (27)
where the index 7 is over adjacent energy regions—the
left side band (I), the center peak signal region (c), and
the right side band (r)—and the expected number of
19

> 800

2 i Signal region

5 [JSideband region

O 600 ---- Background model

1430 1440 1450 1460 1470 1480 1490
Energy (keV)

Fig. 21: Events that pass the basic quality cuts with
M=1 for a single dataset in the °K 1461 keV peak
region.

>

215 Signal region

2

5 ({_]Sideband region

1S) ---- Background model
10

1430 1440 1450 1460 1470 1480 1490
Energy (keV)

Fig. 22: Events that pass the basic quality cuts and fail
the M=1 cut for a single dataset in the 4°K 1461 keV
peak region.

counts in each region [E;,;, E;,2] is

A= [ SF yaE +8; (28)

JE 1

where f(b) is a linear function describing the back-
ground between Ej; and E,.2, 5; = S, = 0, and S, is
the neat signal count in the peak signal region. We per-
form a Bayesian counting analysis with BAT to extract
the posteriors for the neat signal counts. A probability
distribution for the AC efficiency is evaluated by taking
random samples of the BAT posteriors for S.pass and
Sc,fail and combining each sample-pair (Tipaxeitfui) te)
compute €4c. The resulting probability distribution for
the AC efficiency on the °K 7 peak is assumed to be the
same at Qgg. Figures 21 and 22 show the *°K peak fit
region with M=1 and M>1, respectively, for a single

g
3 x, 0.02
2 | 8
z a
2 003+ 7 0.01
£ =
2 0.007400 4600 4800 5000
& 0.02 Counts
aa)
Qa
&0.010;,
ook 0.005
0.000 20 40 60
Counts
n n
9.056 0.97 0.98 0.99 1.00

Efficiency

Fig. 23: AC efficiency prior probability distribution for
a single dataset. Posterior for the number of events
above background in the #°K 1461 keV peak region that
passed basic quality cuts with M = 1 (M > 1) for the cor-
responding dataset is shown in the top (bottom) inset.

dataset. The corresponding posterior probability distri-
butions for the neat signal counts are shown in Fig. 23
for M=1 in the top inset and M> 1 in the bottom in-
set. The AC efficiency probability distribution for the
single dataset is shown in Fig. 23.

11.6 Pulse shape discrimination efficiency

The pulse shape discrimination (PSD) efficiency is cal-
culated from the physics data after performing basic
quality cuts and the AC cut (M=1). The PSD effi-
ciency is the probability of preserving a physical event
upon applying the NRE threshold cut (see Sec. 8). Un-
like the AC efficiency, the PSD efficiency is assumed to
be energy dependent, so we evaluate the correspond-
ing efficiency on several y peaks in the physics spec-
trum and extrapolate to Qgg. Only peaks with reason-
able fit quality with respect to the lineshape are con-
sidered in evaluating the dataset level PSD efficiency,
€psp. Similar to the AC efficiency evaluation, we use a
Bayesian counting analysis to extract the posteriors for
Se,pass and S¢, fait for each of the selected dataset-peaks,
then combine their posteriors numerically to obtain the
energy-dependent PSD efficiency probability distribu-
tions. The probability distribution for epgp of each 7
peak is fit to a Gaussian function in order to obtain a
smooth distribution, but only the physical distribution
range between 0 and 1 is used. A posterior for the PSD
efficiency at Qa is extracted by performing a combined
fit of the Gaussian distributions to a first-order polyno-
mial function. For the 2t-yr 0188 decay analysis, the

iS)
5

b
‘¢ GE Base cuts
2
x 40
K
% Co
~ |
e
5
ie}
oO
10!
10°

1000 2000

( Base cuts + AC

3000

Base cuts + AC + PSD

2105

4000 5000 6000

Energy (keV)

Fig. 24: Blinded physics spectrum for the total 2t-yr data release. The shaded area indicates the salted peak

region at Qgg.

exposure-weighted AC efficiency is 99.80(5)% and the
exposure-weighted PSD efficiency is 97.9(18)% [1].

The total analysis efficiency for each dataset is cal-
culated by combining the PDFs of all the corresponding
efficiencies numerically, as described in Sec. 11.4. The
resulting distribution is used as a dataset-dependent
prior PDF for the total efficiency in the 01,38 decay fit.
The exposure-weighted total analysis efficiency for the
0vB8 decay analysis is 93.4(18)% [1].

12 Physics analyses

An unprecedented amount of high-quality data has been
collected to perform a high-sensitivity search for the
OvBB decay of °°Te. Using the current data analy-
sis procedure, described in this paper, we present the
blinded physics spectrum from over 2t-yr of TeO2 an-
alyzed exposure in Fig. 24. After performing our search
for the 0v86 decay peak in the ROI of the unblinded
spectrum, we set the most stringent limit on the 0v66
decay half-life of 8°Te. This result is reported in [1].
CUORE leverages the extensive amount of data ac-
quired to undertake a variety of physics analyses. One
crucial physics analysis involves constructing a detailed
background model to identify the radioactive contami-
nation that contributes to our data, as detailed in [41].
This model is essential for improving the sensitivity of
our primary search and for the background predictions
of the next-generation experiment, CUPID [42], which
will use the same technology and infrastructure. Our
robust background model allows for a precise measure-
ment of the !°°Te 2188 decay half-life and for dedicated
spectral shape studies for the cross-validation of the

nuclear models [21] and searches for Beyond Standard
Physics (BSM) effects. In addition, we investigate muon
interactions; profiting from the high granularity of the
CUORE detector, we reconstruct muon tracks through
the detector to further refine our understanding of the
background. Another significant multi-crystal analysis
focuses on the search for Fractionally Charged Particles
(FCP) [35], which could provide insights to BSM. By
employing advanced denoising techniques, we are also
able to perform very sensitive low-frequency noise stud-
ies on long timescales; this allowed us to identify the
impact of marine microseisms on the detector resolu-
tion [43,44]. Finally, the keV-scale thresholds achieved
with the described CUORE data analysis procedure en-
ables low energy studies [34], which are crucial for in-
vestigating many rare event signals, including potential
dark matter interactions.

13 Conclusions

The CUORE experiment has made significant advances
in the development and optimization of analysis tools
used to manage and interpret the data collected by
its cryogenic calorimeters. These tools, initially built
for CUORE prototypes, have been refined to handle
the challenges of acquiring and processing data from
~1000 channels. The automated data analysis methods
have facilitated the production of high-quality datasets.
The optimized analysis tools have allowed CUORE to
conduct a high-sensitivity search for the 0vG8 decay
of °Te using over 2t-yr TeO2 exposure, the largest
dataset ever collected and analyzed for this kind of de-
tector technology. Overall, these analysis tools have en-

21

hanced our ability to explore rare events, thereby con-
tributing to the overall scientific output of CUORE.

Acknowledgements The CUORE Collaboration thanks the
directors and staff of the Laboratori Nazionali del Gran Sasso
and the technical staff of our laboratories. This work was sup-
ported by the Istituto Nazionale di Fisica Nucleare (INFN);
the National Science Foundation under Grant Nos. NSF-PHY-
0605119, NSF-PHY-0500337, NSF-PHY-0855314, NSF-PHY-
0902171, NSF-PHY-0969852, NSF-PHY-1307204, NSF-PHY-
1314881, NSF-PHY-1401832, NSF-PHY-1913374, and NSF-
PHY-2412377; Yale University, Johns Hopkins University, and
University of Pittsburgh. This material is also based upon
work supported by the US Department of Energy (DOE) Of
fice of Science under Contract Nos. DE-AC02-05CH11231,
and DE-AC52-07NA27344; by the DOE Office of Science,
Office of Nuclear Physics under Contract Nos. DE-FG02-
08ER41551, DE-FG03-00ER41138, DE-SC0012654, DE-SC0-
020423, DE-SC0019316, and DE-SC0011091. This research
used resources of the National Energy Research Scientific
Computing Center (NERSC). This work makes use of both
the DIANA data analysis and APOLLO data acquisition soft-
ware packages, which were developed by the CUORICINO,
CUORE, LUCIFER, and CUPID-0 Collaborations. The au-
thors acknowledge the Advanced Research Computing at Vir-
ginia Tech and the Yale Center for Research Computing for
providing computational resources and technical support that.
have contributed to the results reported within this paper.

References

1. D.Q. Adams, et al., Science 0(0), eadp6474 (2025). DOT
10.1126/science.adp6474

2. D.Q. Adams, et al., Nature 604(7904), 53 (2022). DOI
10.1038 /s41586-022-04497-4

3. O. Azzolini, et al., Phys. Rev. Lett. 129(11), 111801
(2022). DOI 10.1103/PhysRevLett.129.111801

4. A. Agrawal, et al., Phys. Rev. Lett. 134, 082501 (2025).
DOI 10.1103/PhysRevLett.134.082501

5. M. Agostini, et al., Phys. Rev. Lett. 125, 252502 (2020).
DOI 10.1103/PhysRevLett.125.252502

6. S. Abe, et al., Phys. Rev. Lett. 130(5), 051801 (2023).
DOI 10.1103/PhysRevLett.130.051801

7. C. Arnaboldi, et al., JINST 18(02), P02026 (2018). DOT
10.1088/1748-0221/13/02/P02026

8. P. Carniti, et al., Review of Scientific Instruments 87(5),
054706 (2016). DOI 10.1063/1.4948390

9. K. Alfonso, et al., JINST 13(02), P02029 (2018). DOI
10.1088/1748-0221/13/02/P02029

10. D.Q. Adams, et al., JINST 17(11), P11023 (2022). DOI
10.1088 /1748-0221/17/11/P11023

11. K. Alfonso, et al., Nucl. Instrum. Methods A 1008,
165451 (2021). DOI 10.1016/j.nima.2021.165451

12. V. Dompe, et al., J. Low Temp. Phys. 200(5-6), 286
(2020). DOT 10.1007/s10909-020-02435-0

13. A. D’Addabbo, et al., Cryogenics 93, 56 (2018). DOI
10.1016/j.cryogenics.2018.05.001

14. C. Alduino, et al., JINST 11(07), P07009 (2016). DOI
10.1088/1748-0221/11/07/P07009

15. M. Biassoni, O. Cremonesi, Progress in Particle and Nu-
clear Physics 114, 103803 (2020). DOI 10.1016/j.ppnp.
2020.103803

16. S. Rahaman, et al., Phys. Lett. B 703, 412 (2011). DOI
10.1016 /j.physletb.2011.07.078

17.

18.

20.

21.

22.

23.

24.

26.

27.

28.

29.

40.

Al.

42.

43.

44,

E. Andreotti, et al., Nucl. Instrum. Methods A 664(1),
161 (2012). DOI 10.1016/j.nima.2011.10.065

I. Nutini, J. Low Temp. Phys. 199(1-2), 519 (2020). DOI
10.1007 /s10909-020-02402-9

C. Alduino, et al., Cryogenics 102, 9 (2019). DOI 10.
1016/j.cryogenics.2019.06.011

D.Q. Adams, et al., Progress in Particle and Nuclear
Physics 122, 103902 (2021). DOI 10.1016/j-ppnp.2021.
103902

C. Bucci, et al. CUORE latest results and prospects
(2024). DOI 10.5281/zenodo.12706030. Talk given at
the Neutrino 2024 Conference, Milano, Italy, June, 2024
C. Alduino, et al., Phys. Rev. Lett. 120(13), 132501
(2018). DOI 10.1103/PhysRevLett.120.132501

D. Adams, et al., Phys. Rev. Lett. 124(12), 122501
(2020). DOI 10.1103/PhysRevLett.124.122501

S. Di Domizio, et al., JINST 13(12), P12003 (2018). DOI
10.1088/1748-0221/13/12/P12003

5. R. Brun, F. Rademakers, Nucl. Instrum. Methods A

389(1), 81 (1997). DOI 10.1016/S0168-9002(97)00048-X
C. Alduino, et al., Phys. Rev. C 93(4), 045503 (2016).
DOT 10.1103/PhysRevC.93.045503

K.J. Vetter, et al., Eur. Phys. J. C 84(3), 243 (2024).
DOI 10.1140/epjc/s10052-024-12595-y

C. Bucci, et al., JINST 12(12), P12013 (2017). DOT
10.1088 /1748-0221/12/12/P12013

C. Alduino, et al., Eur. Phys. J. C 77(12), 857 (2017).
DOI 10.1140/epjc/s10052-017-5433-1

A. Branca, J. Phys. Conf. Ser. 1468, 012118 (2020). DOI
10.1088 /1742-6596/1468/1/012118

. E. Gatti, P.F. Manfredi, Riv. Nuovo Cim. 9N1, 1 (1986).

DOI 10.1007/BF02822156

. E. Andreotti, et al., Astrop. Phys. 34(11), 822 (2011).

DOI 10.1016/j.astropartphys.2011.02.002

. A. Alessandrello, et al., Nucl. Instrum. Methods A

412(2), 454 (1998). DOI 10.1016/S0168-9002(98)00458-6

. D.Q. Adams, et al., (2025). Paper in preparation.
_ D.Q. Adams, et al., Phys. Rev. Lett. 133, 241801 (2024).

DOI 10.1103/PhysRevLett.133.241801

. C. Alduino, et al., Eur. Phys. J. C 77(8) (2017). DOI

10.1140/epjc/s10052-017-5080-6

. R.G. Huang, (2021). [Ph. D. thesis, University of Califor-

nia - Berkeley]

. D.Q. Adams, et al., Phys. Rev. Lett. 129, 222501 (2022).

DOI 10.1103/PhysRevLett.129.222501

. D.Q. Adams, et al., Phys. Rev. C 105, 065504 (2022).

DOI 10.1103/PhysRevC.105.065504

A. Caldwell, D. Kollar, K. Kréninger, Computer Physics
Communications 180, 2197 (2009). DOI 10.1016/j.cpc.
2009.06.026

D.Q. Adams, et al., Phys. Rev. D 110, 052003 (2024).
DOI 10.1103/PhysRevD.110.052003

K. Alfonso, et al., Eur. Phys. J. C 85, 737 (2025). DOI
10.1140/epjc/s10052-025-14352-1

L. Aragao, et al., Eur. Phys. J. C 84(7), 728 (2024). DOI
10.1140/epjc/s10052-024- 13065-1

D.Q. Adams, et al., (2025). Paper in preparation.
